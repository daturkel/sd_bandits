{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "\n",
    "root_dir = os.path.expanduser('~/sd_bandits')\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sd_bandits.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obp.policy import BernoulliTS, EpsilonGreedy, Random, LinEpsilonGreedy,\\\n",
    "                       LinTS, LinUCB, LogisticEpsilonGreedy, LogisticTS, LogisticUCB\n",
    "\n",
    "from obp.ope.estimators import DirectMethod, DoublyRobust, DoublyRobustWithShrinkage,\\\n",
    "                               InverseProbabilityWeighting, ReplayMethod,\\\n",
    "                               SelfNormalizedDoublyRobust, SelfNormalizedInverseProbabilityWeighting,\\\n",
    "                               SwitchDoublyRobust, SwitchInverseProbabilityWeighting\n",
    "\n",
    "from obp.ope.regression_model import RegressionModel\n",
    "\n",
    "from obp.dataset import OpenBanditDataset\n",
    "from sd_bandits.deezer.dataset import DeezerDataset\n",
    "\n",
    "from obp.simulator.simulator import run_bandit_simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "policy_dict = {'BernoulliTS':BernoulliTS,\n",
    "               'EpsilonGreedy':EpsilonGreedy,\n",
    "               'Random':Random,\n",
    "               'LinEpsilonGreedy':LinEpsilonGreedy,\n",
    "               'LinTS':LinTS,\n",
    "               'LinUCB':LinUCB,\n",
    "               'LogisticEpsilonGreedy':LogisticEpsilonGreedy,\n",
    "               'LogisticTS':LogisticTS,\n",
    "               'LogisticUCB':LogisticUCB}\n",
    "\n",
    "def build_policy_spec(policy_key, parameter_dict, policy_name=None, output='./policy_yamls/'):\n",
    "    '''\n",
    "    Constructs a yaml output file specifying the type of \n",
    "    policy and the policy paramters\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    policy_key: str\n",
    "        The policy name\n",
    "    parameter_dict: dict\n",
    "        The dict containing {kwarg: value}\n",
    "    policy_name: str\n",
    "        The name of the policy+configuration, if not\n",
    "        specified, will be automatically generated\n",
    "        via timestamp\n",
    "    output: str\n",
    "        Path to directory to store\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    policy: policy\n",
    "        The policy with specified parameters\n",
    "    '''\n",
    "    #Set name via timestamp if not specified\n",
    "    if policy_name==None:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H%M%S\")\n",
    "        policy_name = '{}_{}'.format(policy_key, current_time)\n",
    "    \n",
    "    #Build dict structure\n",
    "    yaml_dict = {}\n",
    "    yaml_dict['name'] = policy_name\n",
    "    yaml_dict['policy_type'] = policy_key\n",
    "    yaml_dict['parameters'] = parameter_dict\n",
    "    \n",
    "    #Set output folder\n",
    "    output_folder = os.path.join(output, policy_name)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    with open(os.path.join(output_folder, 'policy_spec.yaml'), 'w') as file:\n",
    "        yaml.dump(yaml_dict, file)\n",
    "        \n",
    "    policy = policy_dict[policy_key](**parameter_dict)\n",
    "    \n",
    "    return policy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliTS(n_actions=5, len_list=3, batch_size=5, random_state=None, alpha=array([1., 1., 1., 1., 1.]), beta=array([1., 1., 1., 1., 1.]), is_zozotown_prior=False, campaign=None, policy_name='bts')\n"
     ]
    }
   ],
   "source": [
    "policy_key_test = 'BernoulliTS'\n",
    "policy_name_test = 'Bernoulli_test'\n",
    "policy_params_test = {'n_actions':5, 'len_list':3, 'batch_size':5}\n",
    "\n",
    "policy_test = build_policy_spec(policy_key_test, policy_params_test,\\\n",
    "                  policy_name=policy_name_test)\n",
    "\n",
    "print(policy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_policy_from_spec(policy_folder):\n",
    "    '''\n",
    "    Constructs a yaml output file specifying the type of \n",
    "    policy and the policy paramters\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    policy_folder: str\n",
    "        The folder containing the policy spec\n",
    "    Returns\n",
    "    ------------\n",
    "    policy: policy\n",
    "        The policy loaded from the spec yaml\n",
    "    '''\n",
    "    with open(os.path.join(policy_folder, 'policy_spec.yaml'), 'r') as file:\n",
    "        yaml_dict = yaml.load(file)\n",
    "    \n",
    "    policy_key = yaml_dict['policy_type']\n",
    "    parameter_dict = yaml_dict['parameters']\n",
    "    \n",
    "    policy = policy_dict[policy_key](**parameter_dict)\n",
    "   \n",
    "    return policy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliTS(n_actions=5, len_list=3, batch_size=5, random_state=None, alpha=array([1., 1., 1., 1., 1.]), beta=array([1., 1., 1., 1., 1.]), is_zozotown_prior=False, campaign=None, policy_name='bts')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-fd36e1bd954d>:16: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_dict = yaml.load(file)\n"
     ]
    }
   ],
   "source": [
    "policy_load_test = './policy_yamls/Bernoulli_test'\n",
    "\n",
    "policy_load = load_policy_from_spec(policy_load_test)\n",
    "print(policy_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_dict = {'DirectMethod':DirectMethod,\n",
    "                  'DoublyRobust':DoublyRobust,\n",
    "                  'DoublyRobustWithShrinkage':DoublyRobustWithShrinkage,\n",
    "                  'InverseProbabilityWeighting':InverseProbabilityWeighting,\n",
    "                  'ReplayMethod':ReplayMethod,\n",
    "                  'SelfNormalizedDoublyRobust':SelfNormalizedDoublyRobust,\n",
    "                  'SelfNormalizedInverseProbabilityWeighting':SelfNormalizedInverseProbabilityWeighting,\n",
    "                  'SwitchDoublyRobust':SwitchDoublyRobust,\n",
    "                  'SwitchInverseProbabilityWeighting':SwitchInverseProbabilityWeighting}\n",
    "\n",
    "policy_dict = {'BernoulliTS':BernoulliTS,\n",
    "               'EpsilonGreedy':EpsilonGreedy,\n",
    "               'Random':Random,\n",
    "               'LinEpsilonGreedy':LinEpsilonGreedy,\n",
    "               'LinTS':LinTS,\n",
    "               'LinUCB':LinUCB,\n",
    "               'LogisticEpsilonGreedy':LogisticEpsilonGreedy,\n",
    "               'LogisticTS':LogisticTS,\n",
    "               'LogisticUCB':LogisticUCB}\n",
    "\n",
    "dataset_dict = {'obp': OpenBanditDataset,\n",
    "                'deezer': DeezerDataset}\n",
    "\n",
    "\n",
    "def build_obj_spec(obj_key, parameter_dict, experiment_name=None, obj_type='policy', output='./policy_yamls/'):\n",
    "    '''\n",
    "    Constructs a yaml output file specifying the type of \n",
    "    policy and the policy paramters\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    obj_key: str\n",
    "        The policy/estimator/dataset name\n",
    "    parameter_dict: dict\n",
    "        The dict containing parameters for the\n",
    "        obp object {kwarg: value}\n",
    "    experiment_name: str\n",
    "        The associated experiment name, if not\n",
    "        specified, will be automatically generated\n",
    "        via timestamp\n",
    "    obj_type: str\n",
    "        The type of OBP object, should be 'policy'\n",
    "        or 'estimator', throw error otherwise\n",
    "    output: str\n",
    "        Path to directory to store\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    obj_dict: dict\n",
    "        The constructor dict for the object\n",
    "    '''\n",
    "    #Set name via timestamp if not specified\n",
    "    if obj_type not in ['policy','estimator', 'dataset']:\n",
    "        print('Invalid type: {}'.format(obj_type))\n",
    "        return None\n",
    "    \n",
    "    if experiment_name==None:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H%M%S\")\n",
    "        experiment_name = 'experiment_{}'.format(current_time)\n",
    "    \n",
    "    #Build dict structure\n",
    "    obj_dict = {}\n",
    "    obj_dict['name'] = experiment_name\n",
    "    obj_dict['type'] = obj_type\n",
    "    obj_dict['key'] = obj_key\n",
    "    obj_dict['parameters'] = parameter_dict\n",
    "    \n",
    "    #Set output folder\n",
    "    output_folder = os.path.join(output, experiment_name)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    with open(os.path.join(output_folder, '{}_spec.yaml'.format(obj_type)), 'w') as file:\n",
    "        yaml.dump(obj_dict, file)\n",
    "        \n",
    "    return obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj_from_spec(obj_dict_path, return_yaml=False):\n",
    "    '''\n",
    "    Loads policy/estimator from spec dict\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    obj_dict_path: str\n",
    "        Path to configuration dict from build_obj_spec()\n",
    "    return_yaml: bool\n",
    "        If true, returns the config dict\n",
    "    Returns\n",
    "    ------------\n",
    "    obj: obp.policy/obp.estimator/dataset\n",
    "        The policy/estimator loaded from the spec dict\n",
    "    config_dict: dict (optional)\n",
    "        The spec dict\n",
    "    '''\n",
    "    with open(obj_dict_path, 'r') as file:\n",
    "        obj_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "    obj_name = obj_dict['name']\n",
    "    obj_type = obj_dict['type']\n",
    "    obj_key = obj_dict['key']\n",
    "    parameter_dict = obj_dict['parameters']\n",
    "    \n",
    "    if obj_type=='policy':\n",
    "        obj = policy_dict[obj_key](**parameter_dict)\n",
    "    elif obj_type=='estimator':\n",
    "        obj = estimator_dict[obj_key](**parameter_dict)\n",
    "    elif obj_type=='dataset':\n",
    "        parameter_dict['data_path'] = Path(parameter_dict['data_path'])\n",
    "        obj = dataset_dict[obj_key](**parameter_dict)\n",
    "    if return_yaml:\n",
    "        return obj, obj_dict\n",
    "    else:\n",
    "        return obj\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'save_obj_test', 'type': 'policy', 'key': 'BernoulliTS', 'parameters': {'n_actions': 5, 'len_list': 3, 'batch_size': 5}}\n",
      "BernoulliTS(n_actions=5, len_list=3, batch_size=5, random_state=None, alpha=array([1., 1., 1., 1., 1.]), beta=array([1., 1., 1., 1., 1.]), is_zozotown_prior=False, campaign=None, policy_name='bts')\n"
     ]
    }
   ],
   "source": [
    "policy_key_test = 'BernoulliTS'\n",
    "policy_name_test = 'save_obj_test'\n",
    "policy_params_test = {'n_actions':5, 'len_list':3, 'batch_size':5}\n",
    "\n",
    "policy_test = build_obj_spec(policy_key_test, policy_params_test, experiment_name=policy_name_test)\n",
    "\n",
    "print(policy_test)\n",
    "policy_load = load_obj_from_spec('policy_yamls/save_obj_test/policy_spec.yaml')\n",
    "print(policy_load )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'save_obj_test', 'type': 'estimator', 'key': 'DoublyRobustWithShrinkage', 'parameters': {'lambda_': 1}}\n",
      "DoublyRobustWithShrinkage(estimator_name='dr-os', lambda_=1)\n"
     ]
    }
   ],
   "source": [
    "est_key_test = 'DoublyRobustWithShrinkage'\n",
    "est_name_test = 'save_obj_test'\n",
    "est_params_test = {'lambda_':1}\n",
    "\n",
    "est_test = build_obj_spec(est_key_test, est_params_test, experiment_name=est_name_test, obj_type='estimator')\n",
    "\n",
    "print(est_test)\n",
    "est_load = load_obj_from_spec('policy_yamls/save_obj_test/estimator_spec.yaml')\n",
    "print(est_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'save_obj_test', 'type': 'dataset', 'key': 'obp', 'parameters': {'data_path': '~/sd_bandits/data/obd', 'campaign': 'all', 'behavior_policy': 'bts'}}\n",
      "OpenBanditDataset(behavior_policy='bts', campaign='all', data_path=PosixPath('~/sd_bandits/data/obd/bts/all'), dataset_name='obd')\n"
     ]
    }
   ],
   "source": [
    "dataset_key_test = 'obp'\n",
    "dataset_name_test = 'save_obj_test'\n",
    "dataset_params_test = {'data_path': '~/sd_bandits/data/obd',\n",
    "                       'campaign': 'all',\n",
    "                       'behavior_policy': 'bts'}\n",
    "\n",
    "dataset_test = build_obj_spec(dataset_key_test, dataset_params_test, experiment_name=dataset_name_test, obj_type='dataset')\n",
    "\n",
    "print(dataset_test)\n",
    "dataset_load = load_obj_from_spec('policy_yamls/save_obj_test/dataset_spec.yaml')\n",
    "print(dataset_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 19800.55it/s]\n"
     ]
    }
   ],
   "source": [
    "feedback = dataset_load.obtain_batch_bandit_feedback()\n",
    "actions = run_bandit_simulation(bandit_feedback=feedback,\n",
    "                                    policy=policy_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_rounds', 'n_actions', 'action', 'position', 'reward', 'reward_test', 'pscore', 'context', 'action_context'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(feedback.keys())\n",
    "feedback['position'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DoublyRobustWithShrinkage'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(est_load)).split('.')[-1].split(\"'\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_rewards_model = RegressionModel(Ridge(), n_actions=feedback['n_actions'],\\\n",
    "                                   action_context=feedback['action_context'], len_list=dataset_load.len_list)\n",
    "\n",
    "estimated_rewards = estimated_rewards_model.fit_predict(context=feedback['context'],\n",
    "                                                       action=feedback['action'],\n",
    "                                                       reward=feedback['reward'],\n",
    "                                                       pscore=feedback['pscore'],\n",
    "                                                       position=feedback['position'],\n",
    "                                                       action_dist=actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reward', 'action', 'position', 'pscore', 'action_dist', 'estimated_rewards_by_reg_model'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': 0.003091009995921152,\n",
       " '95.0% CI (lower)': 0.0029681474992248637,\n",
       " '95.0% CI (upper)': 0.0032111780298424318}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_args = ['reward', 'action', 'position', 'pscore', 'action',\n",
    "                 'action_dist', 'estimated_rewards_by_reg_model']\n",
    "\n",
    "sub_dict = {}   \n",
    "for key in required_args:\n",
    "\n",
    "    if key=='action_dist':\n",
    "        sub_dict[key] = actions\n",
    "    elif key=='estimated_rewards_by_reg_model':\n",
    "        sub_dict[key] = estimated_rewards\n",
    "    else:\n",
    "        sub_dict[key] = feedback[key]\n",
    "\n",
    "print(sub_dict.keys())\n",
    "est_load.estimate_interval(**sub_dict)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_results = est_load.estimate_interval(reward=feedback[\"reward\"],\n",
    "                                          action=feedback[\"action\"],\n",
    "                                          position=feedback[\"position\"],\n",
    "                                          pscore=feedback[\"pscore\"],\n",
    "                                          action_dist=actions,\n",
    "                                          estimated_rewards_by_reg_model=estimated_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_shell='''#!/bin/bash\n",
    "#SBATCH --job-name=ex_jb\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=16GB\n",
    "#SBATCH --time=100:00:00\n",
    "#SBATCH --output=\"{}\"\n",
    "#SBATCH --export=NONE\n",
    "\n",
    "module purge\n",
    "module load anaconda3/4.3.1\n",
    "\n",
    "source activate sd_bandits_env\n",
    "\n",
    "cd ~/sd_bandits/scripting/\n",
    "\n",
    "python opb_run.py --experiment-dir '{}'\n",
    "'''\n",
    "\n",
    "def build_experiment(experiment_name, policy, estimator, dataset, policy_params,\n",
    "                     estimator_params, dataset_params, output_folder='./policy_yamls/',\n",
    "                     slurm_output='./outputs/'):\n",
    "    '''\n",
    "    Builds full experiment spec folder w/ policy, estimator, and dataset, as well as a\n",
    "    slurm script\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    experiment_name: str\n",
    "        Name of the experiment dir\n",
    "    policy: str\n",
    "        Which obp policy to use\n",
    "    estimator: str\n",
    "        Which obp estimator to use\n",
    "    dataset: str\n",
    "        Which dataset to use ('obp' or 'deezer')\n",
    "    policy_params: dict\n",
    "        Dict for any parameters to construct the policy\n",
    "    estimator_params:\n",
    "        Dict for any parameters to construct the policy\n",
    "    dataset_params:\n",
    "        Dict for any parameters to contruct the ataset object\n",
    "    output_folder: str\n",
    "        Directory that will contain experiment directory\n",
    "    Returns\n",
    "    ------------\n",
    "    None\n",
    "    '''\n",
    "    \n",
    "    policy_dict = build_obj_spec(policy, policy_params, experiment_name=experiment_name,\\\n",
    "                                 obj_type='policy', output=output_folder)\n",
    "    estimator_dict = build_obj_spec(estimator, estimator_params, experiment_name=experiment_name,\\\n",
    "                                    obj_type='estimator', output=output_folder)\n",
    "    dataset_dict = build_obj_spec(dataset, dataset_params, experiment_name=experiment_name,\\\n",
    "                                  obj_type='dataset', output=output_folder)\n",
    "    \n",
    "    experiment_dir = os.path.join(output_folder, experiment_name)\n",
    "    slurm_output = os.path.join(slurm_output, experiment_name+'.out')\n",
    "    slurm_script = script_shell.format(slurm_output, experiment_dir)\n",
    "    \n",
    "    with open(os.path.join(experiment_dir, 'script.sbatch'),'w') as file:\n",
    "        file.write(slurm_script)\n",
    "    print(slurm_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=ex_jb\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --cpus-per-task=4\n",
      "#SBATCH --mem=16GB\n",
      "#SBATCH --time=100:00:00\n",
      "#SBATCH --output=\"./outputs/experiment_test.out\"\n",
      "#SBATCH --export=NONE\n",
      "\n",
      "module purge\n",
      "module load anaconda3/4.3.1\n",
      "\n",
      "source activate sd_bandits_env\n",
      "\n",
      "cd ~/sd_bandits/scripting/\n",
      "\n",
      "python opb_run.py --experiment-dir './policy_yamls/experiment_test'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_test_name = 'experiment_test'\n",
    "\n",
    "policy_key_test = 'BernoulliTS'\n",
    "policy_params_test = {'n_actions':5, 'len_list':3, 'batch_size':5}\n",
    "est_key_test = 'DoublyRobustWithShrinkage'\n",
    "est_params_test = {'lambda_':1}\n",
    "dataset_key_test = 'obp'\n",
    "dataset_params_test = {'data_path': '~/sd_bandits/data/obd',\n",
    "                       'campaign': 'all',\n",
    "                       'behavior_policy': 'bts'}\n",
    "\n",
    "build_experiment(experiment_test_name, policy_key_test, est_key_test, dataset_key_test,\\\n",
    "                 policy_params_test, est_params_test, dataset_params_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SD_Bandits Py3.8",
   "language": "python",
   "name": "sd_bandits_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
