{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Official documentation for OBP](https://zr-obp.readthedocs.io/en/latest/)**\n",
    "\n",
    "## Quick Reference:\n",
    "\n",
    "**OBP: Open Bandit Pipeline** - this software library\n",
    "\n",
    "**OBD: Open Bandit Dataset** - the dataset supplied with it\n",
    "\n",
    "**OPE: off-policy evaluation** - the process of determining how a policy _other than the one that was really run_ woudl have performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidanclaffey/anaconda3/envs/bandits-env/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from obp.dataset import OpenBanditDataset\n",
    "import numpy as np\n",
    "\n",
    "DATASET = \"../data/obd_full\"\n",
    "# DATASET = \"../data/obd\"\n",
    "\n",
    "dataset = OpenBanditDataset(\n",
    "    data_path=Path(DATASET),\n",
    "    campaign=\"all\",\n",
    "    behavior_policy=\"random\"\n",
    ")\n",
    "\n",
    "feedback = dataset.obtain_batch_bandit_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy and Simulator\n",
    "\n",
    "Testing out self-implemented `ExploreThenCommit` and comparing with OBP's `Epsilon Greedy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obp.policy import EpsilonGreedy\n",
    "\n",
    "from sd_bandits.obp_extensions.policy import ExploreThenCommit\n",
    "\n",
    "etc = ExploreThenCommit(\n",
    "    n_actions=dataset.n_actions,\n",
    "    len_list = dataset.len_list,\n",
    "    batch_size=1, # update parameters after every round\n",
    "    random_state=0,\n",
    "    min_n = 30\n",
    ")\n",
    "\n",
    "eps_greedy = EpsilonGreedy(\n",
    "    n_actions=dataset.n_actions,\n",
    "    len_list = dataset.len_list,\n",
    "    batch_size=1, # update parameters after every round\n",
    "    random_state=0,\n",
    "    epsilon=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1374327/1374327 [00:24<00:00, 56349.46it/s]\n",
      "100%|██████████| 1374327/1374327 [00:15<00:00, 89996.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from obp.simulator.simulator import run_bandit_simulation\n",
    "\n",
    "etc_actions = run_bandit_simulation(bandit_feedback=feedback, policy=etc)\n",
    "\n",
    "eps_actions = run_bandit_simulation(bandit_feedback=feedback, policy=eps_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often each action was shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore-Then-Commit\n",
      "[  30   30   30   30   30   30   30   30   30 1259   30   30   30   30\n",
      "   30   30   30   30  629   30   30   30   30   30   30   30  315   30\n",
      "   30   30   30   30   30   30   30   30   30  315   30  315   30   30\n",
      "   30   30   30 3906   30   30   30   30   30   30   30   30   30   30\n",
      "   30   30   30   30   30   30   30   30   30   30   30   30   30   30\n",
      "   30   30   30   30  315  630   30   30   30   30]\n",
      "\n",
      "Epsilon-Greedy\n",
      "[1506   60  572   46   49   38   43   67   41   59   41   38   54   46\n",
      "   42   47   45   41   54   48   38  271   57   45   56   44   35   33\n",
      "   47   45   49   52   34   44 1891   53   31   51   42 1192   51   56\n",
      "   47  571   44   39   46   45   34  810   45   42   42   45   42   42\n",
      "   45   66   39   46   49   40   39   39   43   52   63  147   49   46\n",
      "   53   47   42   46   38  573   43   41  987 2188]\n"
     ]
    }
   ],
   "source": [
    "print('Explore-Then-Commit')\n",
    "print(etc.action_counts)\n",
    "print()\n",
    "print('Epsilon-Greedy')\n",
    "print(eps_greedy.action_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative 'reward' of each action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore-Then-Commit\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00317712 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00317965 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0031746  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0031746  0.         0.0031746  0.         0.\n",
      " 0.         0.         0.         0.00486431 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0031746  0.0031746  0.         0.\n",
      " 0.         0.        ]\n",
      "\n",
      "Epsilon-Greedy\n",
      "[0.00464807 0.         0.00174825 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00581703 0.\n",
      " 0.         0.         0.         0.0159396  0.         0.\n",
      " 0.         0.00175131 0.         0.         0.         0.\n",
      " 0.         0.00246914 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00680272 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.0017452  0.         0.\n",
      " 0.00303951 0.00822669]\n"
     ]
    }
   ],
   "source": [
    "print('Explore-Then-Commit')\n",
    "print(etc.reward_counts)\n",
    "print()\n",
    "print('Epsilon-Greedy')\n",
    "print(eps_greedy.reward_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often each action was clicked on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore-Then-Commit\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  2.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  0. 19.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  0.  0.  0.  0.]\n",
      "\n",
      "Epsilon-Greedy\n",
      "[ 7.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 11.  0.\n",
      "  0.  0.  0. 19.  0.  0.  0.  1.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  3. 18.]\n"
     ]
    }
   ],
   "source": [
    "print('Explore-Then-Commit')\n",
    "print(etc.reward_counts * etc.action_counts)\n",
    "print()\n",
    "print('Epsilon-Greedy')\n",
    "print(eps_greedy.reward_counts * eps_greedy.action_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Off-Policy Evaluation\n",
    "\n",
    "Some off-polict evaluation methods require a base regression model (like the Direct Method and all methods that use the Direct Method). So, we import LinearRegression in this case, although smarter ones can be used\n",
    "\n",
    "OBP allows us to measure multiple OPEs at once using the `OffPolicyEvaluation` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# import open bandit pipeline (obp)\n",
    "from obp.ope import (\n",
    "    OffPolicyEvaluation, \n",
    "    RegressionModel,\n",
    "    DirectMethod,\n",
    "    InverseProbabilityWeighting,\n",
    "    DoublyRobust,\n",
    "    DoublyRobustWithShrinkage,\n",
    "    SelfNormalizedDoublyRobust\n",
    ")\n",
    "\n",
    "regression_model = RegressionModel(\n",
    "    n_actions=dataset.n_actions,\n",
    "    len_list=dataset.len_list,\n",
    "    action_context=dataset.action_context,\n",
    "    base_model=LinearRegression(),\n",
    ")\n",
    "\n",
    "estimated_rewards_by_reg_model = regression_model.fit_predict(\n",
    "    context=feedback[\"context\"],\n",
    "    action=feedback[\"action\"],\n",
    "    reward=feedback[\"reward\"],\n",
    "    position=feedback[\"position\"],\n",
    "    pscore=feedback[\"pscore\"],\n",
    "    n_folds=3, # use 3-fold cross-fitting,\n",
    "    random_state=12345,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore then commit analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope = OffPolicyEvaluation(\n",
    "    bandit_feedback=feedback,\n",
    "    ope_estimators=[InverseProbabilityWeighting(), DirectMethod(), DoublyRobust(),\n",
    "                    DoublyRobustWithShrinkage(lambda_ = 1e3), SelfNormalizedDoublyRobust()]\n",
    ")\n",
    "\n",
    "# `summarize_off_policy_estimates` returns pandas dataframes including the OPE results\n",
    "estimated_policy_value, estimated_interval = ope.summarize_off_policy_estimates(\n",
    "    action_dist=etc_actions, \n",
    "    estimated_rewards_by_reg_model=estimated_rewards_by_reg_model,\n",
    "    random_state=12345,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground-truth policy value of the random policy\n",
    "# , which is the empirical mean of the factual (observed) rewards (on-policy estimation)\n",
    "ground_truth = feedback['reward'].mean()\n",
    "\n",
    "# calculate estimated policy value of the evaluation policy (the BernoulliTS policy)\n",
    "# relative to the ground-truth policy value of the behavior policy (the Random policy here)\n",
    "estimated_policy_value['relative_estimated_policy_value'] =\\\n",
    "        estimated_policy_value.estimated_policy_value / ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimated_policy_value</th>\n",
       "      <th>relative_estimated_policy_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ipw</th>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.520134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dm</th>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.994374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr</th>\n",
       "      <td>0.003312</td>\n",
       "      <td>0.954514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr-os</th>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.988988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sndr</th>\n",
       "      <td>0.005779</td>\n",
       "      <td>1.665754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimated_policy_value  relative_estimated_policy_value\n",
       "ipw                  0.001805                         0.520134\n",
       "dm                   0.003450                         0.994374\n",
       "dr                   0.003312                         0.954514\n",
       "dr-os                0.003431                         0.988988\n",
       "sndr                 0.005779                         1.665754"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_policy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>95.0% CI (lower)</th>\n",
       "      <th>95.0% CI (upper)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ipw</th>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dm</th>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.003457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr</th>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.004153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr-os</th>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.003547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sndr</th>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.007248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean  95.0% CI (lower)  95.0% CI (upper)\n",
       "ipw    0.001853          0.001106          0.002650\n",
       "dm     0.003449          0.003432          0.003457\n",
       "dr     0.003360          0.002632          0.004153\n",
       "dr-os  0.003437          0.003340          0.003547\n",
       "sndr   0.005863          0.004593          0.007248"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization for Epsilon-Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope.visualize_off_policy_estimates(\n",
    "    action_dist=eps_actions,\n",
    "    estimated_rewards_by_reg_model=estimated_rewards_by_reg_model,\n",
    "    is_relative=True,\n",
    "    random_state=12345,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization for ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope.visualize_off_policy_estimates(\n",
    "    action_dist=etc_actions,\n",
    "    estimated_rewards_by_reg_model=estimated_rewards_by_reg_model,\n",
    "    is_relative=True,\n",
    "    random_state=12345,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandits-env",
   "language": "python",
   "name": "bandits-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
